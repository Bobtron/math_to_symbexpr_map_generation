2021-01-11 22:23:07 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': True}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'broadcast_buffers': False, 'distributed_wrapper': 'DDP', 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'tpu': False, 'distributed_num_procs': 0}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'model_parallel_size': 1, 'distributed_rank': 0}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none'), 'task': Namespace(_name='translation', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none'), 'criterion': Namespace(_name='label_smoothed_cross_entropy', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none'), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None}
2021-01-11 22:23:07 | INFO | fairseq.tasks.translation | [sym] dictionary: 32 types
2021-01-11 22:23:07 | INFO | fairseq.tasks.translation | [math] dictionary: 32 types
2021-01-11 22:23:07 | INFO | fairseq.data.data_utils | loaded 18 examples from: data-bin/valid.sym-math.sym
2021-01-11 22:23:07 | INFO | fairseq.data.data_utils | loaded 18 examples from: data-bin/valid.sym-math.math
2021-01-11 22:23:07 | INFO | fairseq.tasks.translation | data-bin/ valid sym-math 18 examples
2021-01-11 22:23:07 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(32, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(32, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=32, bias=False)
  )
)
2021-01-11 22:23:07 | INFO | fairseq_cli.train | task: TranslationTask
2021-01-11 22:23:07 | INFO | fairseq_cli.train | model: TransformerModel
2021-01-11 22:23:07 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion)
2021-01-11 22:23:07 | INFO | fairseq_cli.train | num. model params: 44171264 (num. trained: 44171264)
2021-01-11 22:23:07 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2021-01-11 22:23:07 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2021-01-11 22:23:07 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and batch size per GPU = None
2021-01-11 22:23:07 | INFO | fairseq.trainer | no existing checkpoint found checkpoints/checkpoint_last.pt
2021-01-11 22:23:07 | INFO | fairseq.trainer | loading train data for epoch 1
2021-01-11 22:23:07 | INFO | fairseq.data.data_utils | loaded 402 examples from: data-bin/train.sym-math.sym
2021-01-11 22:23:07 | INFO | fairseq.data.data_utils | loaded 402 examples from: data-bin/train.sym-math.math
2021-01-11 22:23:07 | INFO | fairseq.tasks.translation | data-bin/ train sym-math 402 examples
2021-01-11 22:23:07 | INFO | fairseq.trainer | begin training epoch 1
2021-01-11 22:23:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:23:41 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.365 | nll_loss 4.179 | ppl 18.12 | wps 0 | wpb 1056 | bsz 18 | num_updates 14
2021-01-11 22:23:41 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:23:41 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint1.pt after 14 updates
2021-01-11 22:23:41 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint1.pt
2021-01-11 22:23:42 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint1.pt (epoch 1 @ 14 updates, score 4.365) (writing took 0.9815079607069492 seconds)
2021-01-11 22:23:42 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2021-01-11 22:23:42 | INFO | train | epoch 001 | loss 4.985 | nll_loss 4.903 | ppl 29.92 | wps 661 | ups 0.4 | wpb 1624.6 | bsz 28.7 | num_updates 14 | lr 1.75e-06 | gnorm 19.896 | train_wall 33 | wall 35
2021-01-11 22:23:42 | INFO | fairseq.trainer | begin training epoch 2
2021-01-11 22:24:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:24:16 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.038 | nll_loss 3.691 | ppl 12.91 | wps 0 | wpb 1056 | bsz 18 | num_updates 28 | best_loss 4.038
2021-01-11 22:24:16 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:24:16 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint2.pt after 28 updates
2021-01-11 22:24:17 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint2.pt
2021-01-11 22:24:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint2.pt (epoch 2 @ 28 updates, score 4.038) (writing took 12.640273608267307 seconds)
2021-01-11 22:24:29 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2021-01-11 22:24:29 | INFO | train | epoch 002 | loss 4.206 | nll_loss 3.968 | ppl 15.65 | wps 484.8 | ups 0.3 | wpb 1624.6 | bsz 28.7 | num_updates 28 | lr 3.5e-06 | gnorm 7.2 | train_wall 33 | wall 82
2021-01-11 22:24:29 | INFO | fairseq.trainer | begin training epoch 3
2021-01-11 22:25:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:25:03 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 3.732 | nll_loss 3.433 | ppl 10.8 | wps 0 | wpb 1056 | bsz 18 | num_updates 42 | best_loss 3.732
2021-01-11 22:25:03 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:25:03 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint3.pt after 42 updates
2021-01-11 22:25:03 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint3.pt
2021-01-11 22:25:42 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint3.pt (epoch 3 @ 42 updates, score 3.732) (writing took 39.14765448495746 seconds)
2021-01-11 22:25:42 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2021-01-11 22:25:42 | INFO | train | epoch 003 | loss 3.962 | nll_loss 3.679 | ppl 12.8 | wps 310.1 | ups 0.19 | wpb 1624.6 | bsz 28.7 | num_updates 42 | lr 5.25e-06 | gnorm 3.729 | train_wall 33 | wall 155
2021-01-11 22:25:42 | INFO | fairseq.trainer | begin training epoch 4
2021-01-11 22:26:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:26:17 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 3.703 | nll_loss 3.389 | ppl 10.48 | wps 0 | wpb 1056 | bsz 18 | num_updates 56 | best_loss 3.703
2021-01-11 22:26:17 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:26:17 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint4.pt after 56 updates
2021-01-11 22:26:17 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint4.pt
2021-01-11 22:26:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint4.pt (epoch 4 @ 56 updates, score 3.703) (writing took 37.36807572841644 seconds)
2021-01-11 22:26:54 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2021-01-11 22:26:54 | INFO | train | epoch 004 | loss 3.864 | nll_loss 3.601 | ppl 12.14 | wps 316.3 | ups 0.19 | wpb 1624.6 | bsz 28.7 | num_updates 56 | lr 7e-06 | gnorm 2.217 | train_wall 34 | wall 227
2021-01-11 22:26:54 | INFO | fairseq.trainer | begin training epoch 5
2021-01-11 22:27:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:27:28 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 3.663 | nll_loss 3.352 | ppl 10.21 | wps 0 | wpb 1056 | bsz 18 | num_updates 70 | best_loss 3.663
2021-01-11 22:27:28 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:27:28 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint5.pt after 70 updates
2021-01-11 22:27:29 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint5.pt
2021-01-11 22:27:30 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint5.pt (epoch 5 @ 70 updates, score 3.663) (writing took 1.7223962619900703 seconds)
2021-01-11 22:27:30 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2021-01-11 22:27:30 | INFO | train | epoch 005 | loss 3.814 | nll_loss 3.531 | ppl 11.56 | wps 632.6 | ups 0.39 | wpb 1624.6 | bsz 28.7 | num_updates 70 | lr 8.75e-06 | gnorm 2.154 | train_wall 33 | wall 263
2021-01-11 22:27:30 | INFO | fairseq.trainer | begin training epoch 6
2021-01-11 22:28:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:28:04 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 3.637 | nll_loss 3.318 | ppl 9.97 | wps 0 | wpb 1056 | bsz 18 | num_updates 84 | best_loss 3.637
2021-01-11 22:28:04 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:28:04 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint6.pt after 84 updates
2021-01-11 22:28:05 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint6.pt
2021-01-11 22:28:06 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint6.pt (epoch 6 @ 84 updates, score 3.637) (writing took 1.7580639012157917 seconds)
2021-01-11 22:28:06 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2021-01-11 22:28:06 | INFO | train | epoch 006 | loss 3.788 | nll_loss 3.507 | ppl 11.37 | wps 628.5 | ups 0.39 | wpb 1624.6 | bsz 28.7 | num_updates 84 | lr 1.05e-05 | gnorm 2.646 | train_wall 34 | wall 299
2021-01-11 22:28:06 | INFO | fairseq.trainer | begin training epoch 7
2021-01-11 22:28:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:28:41 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 3.588 | nll_loss 3.265 | ppl 9.61 | wps 0 | wpb 1056 | bsz 18 | num_updates 98 | best_loss 3.588
2021-01-11 22:28:41 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:28:41 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint7.pt after 98 updates
2021-01-11 22:28:41 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint7.pt
2021-01-11 22:28:42 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint7.pt (epoch 7 @ 98 updates, score 3.588) (writing took 1.7429919838905334 seconds)
2021-01-11 22:28:42 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2021-01-11 22:28:42 | INFO | train | epoch 007 | loss 3.739 | nll_loss 3.453 | ppl 10.95 | wps 631.3 | ups 0.39 | wpb 1624.6 | bsz 28.7 | num_updates 98 | lr 1.225e-05 | gnorm 1.926 | train_wall 33 | wall 335
2021-01-11 22:28:42 | INFO | fairseq.trainer | begin training epoch 8
2021-01-11 22:29:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:29:17 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 3.542 | nll_loss 3.208 | ppl 9.24 | wps 0 | wpb 1056 | bsz 18 | num_updates 112 | best_loss 3.542
2021-01-11 22:29:17 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:29:17 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint8.pt after 112 updates
2021-01-11 22:29:17 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint8.pt
2021-01-11 22:29:18 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint8.pt (epoch 8 @ 112 updates, score 3.542) (writing took 1.772343698889017 seconds)
2021-01-11 22:29:18 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2021-01-11 22:29:18 | INFO | train | epoch 008 | loss 3.682 | nll_loss 3.387 | ppl 10.46 | wps 628.1 | ups 0.39 | wpb 1624.6 | bsz 28.7 | num_updates 112 | lr 1.4e-05 | gnorm 1.617 | train_wall 34 | wall 371
2021-01-11 22:29:19 | INFO | fairseq.trainer | begin training epoch 9
2021-01-11 22:29:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:29:53 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 3.477 | nll_loss 3.134 | ppl 8.78 | wps 0 | wpb 1056 | bsz 18 | num_updates 126 | best_loss 3.477
2021-01-11 22:29:53 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:29:53 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint9.pt after 126 updates
2021-01-11 22:29:53 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint9.pt
2021-01-11 22:29:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint9.pt (epoch 9 @ 126 updates, score 3.477) (writing took 1.7375135645270348 seconds)
2021-01-11 22:29:55 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2021-01-11 22:29:55 | INFO | train | epoch 009 | loss 3.621 | nll_loss 3.317 | ppl 9.97 | wps 628.5 | ups 0.39 | wpb 1624.6 | bsz 28.7 | num_updates 126 | lr 1.575e-05 | gnorm 1.951 | train_wall 34 | wall 408
2021-01-11 22:29:55 | INFO | fairseq.trainer | begin training epoch 10
2021-01-11 22:30:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:30:29 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 3.38 | nll_loss 3.018 | ppl 8.1 | wps 0 | wpb 1056 | bsz 18 | num_updates 140 | best_loss 3.38
2021-01-11 22:30:29 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:30:29 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint10.pt after 140 updates
2021-01-11 22:30:29 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint10.pt
2021-01-11 22:30:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint10.pt (epoch 10 @ 140 updates, score 3.38) (writing took 12.218885317444801 seconds)
2021-01-11 22:30:41 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2021-01-11 22:30:41 | INFO | train | epoch 010 | loss 3.547 | nll_loss 3.231 | ppl 9.39 | wps 487.6 | ups 0.3 | wpb 1624.6 | bsz 28.7 | num_updates 140 | lr 1.75e-05 | gnorm 2.636 | train_wall 34 | wall 454
2021-01-11 22:30:41 | INFO | fairseq.trainer | begin training epoch 11
2021-01-11 22:31:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:31:16 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 3.201 | nll_loss 2.806 | ppl 6.99 | wps 0 | wpb 1056 | bsz 18 | num_updates 154 | best_loss 3.201
2021-01-11 22:31:16 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:31:16 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint11.pt after 154 updates
2021-01-11 22:31:16 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint11.pt
2021-01-11 22:31:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint11.pt (epoch 11 @ 154 updates, score 3.201) (writing took 37.09003545343876 seconds)
2021-01-11 22:31:53 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2021-01-11 22:31:53 | INFO | train | epoch 011 | loss 3.432 | nll_loss 3.093 | ppl 8.53 | wps 317.7 | ups 0.2 | wpb 1624.6 | bsz 28.7 | num_updates 154 | lr 1.925e-05 | gnorm 2.382 | train_wall 34 | wall 526
2021-01-11 22:31:53 | INFO | fairseq.trainer | begin training epoch 12
2021-01-11 22:32:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:32:27 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 3.004 | nll_loss 2.519 | ppl 5.73 | wps 0 | wpb 1056 | bsz 18 | num_updates 168 | best_loss 3.004
2021-01-11 22:32:27 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:32:27 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint12.pt after 168 updates
2021-01-11 22:32:27 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint12.pt
2021-01-11 22:33:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint12.pt (epoch 12 @ 168 updates, score 3.004) (writing took 36.58039217814803 seconds)
2021-01-11 22:33:04 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2021-01-11 22:33:04 | INFO | train | epoch 012 | loss 3.236 | nll_loss 2.849 | ppl 7.2 | wps 322 | ups 0.2 | wpb 1624.6 | bsz 28.7 | num_updates 168 | lr 2.1e-05 | gnorm 3.375 | train_wall 33 | wall 596
2021-01-11 22:33:04 | INFO | fairseq.trainer | begin training epoch 13
2021-01-11 22:33:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:33:38 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 2.896 | nll_loss 2.375 | ppl 5.19 | wps 0 | wpb 1056 | bsz 18 | num_updates 182 | best_loss 2.896
2021-01-11 22:33:38 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:33:38 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint13.pt after 182 updates
2021-01-11 22:33:38 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint13.pt
2021-01-11 22:34:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint13.pt (epoch 13 @ 182 updates, score 2.896) (writing took 34.550513457506895 seconds)
2021-01-11 22:34:12 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2021-01-11 22:34:12 | INFO | train | epoch 013 | loss 3.058 | nll_loss 2.617 | ppl 6.13 | wps 331.1 | ups 0.2 | wpb 1624.6 | bsz 28.7 | num_updates 182 | lr 2.275e-05 | gnorm 3.706 | train_wall 33 | wall 665
2021-01-11 22:34:12 | INFO | fairseq.trainer | begin training epoch 14
2021-01-11 22:34:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:34:47 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 2.884 | nll_loss 2.373 | ppl 5.18 | wps 0 | wpb 1056 | bsz 18 | num_updates 196 | best_loss 2.884
2021-01-11 22:34:47 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:34:47 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint14.pt after 196 updates
2021-01-11 22:34:47 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint14.pt
2021-01-11 22:35:20 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint14.pt (epoch 14 @ 196 updates, score 2.884) (writing took 33.14365708082914 seconds)
2021-01-11 22:35:20 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2021-01-11 22:35:20 | INFO | train | epoch 014 | loss 2.981 | nll_loss 2.519 | ppl 5.73 | wps 337.4 | ups 0.21 | wpb 1624.6 | bsz 28.7 | num_updates 196 | lr 2.45e-05 | gnorm 3.48 | train_wall 33 | wall 733
2021-01-11 22:35:20 | INFO | fairseq.trainer | begin training epoch 15
2021-01-11 22:35:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:35:54 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 2.88 | nll_loss 2.383 | ppl 5.22 | wps 0 | wpb 1056 | bsz 18 | num_updates 210 | best_loss 2.88
2021-01-11 22:35:54 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:35:54 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint15.pt after 210 updates
2021-01-11 22:35:54 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint15.pt
2021-01-11 22:36:26 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint15.pt (epoch 15 @ 210 updates, score 2.88) (writing took 32.23367949202657 seconds)
2021-01-11 22:36:26 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2021-01-11 22:36:26 | INFO | train | epoch 015 | loss 2.95 | nll_loss 2.484 | ppl 5.59 | wps 341.3 | ups 0.21 | wpb 1624.6 | bsz 28.7 | num_updates 210 | lr 2.625e-05 | gnorm 2.988 | train_wall 33 | wall 799
2021-01-11 22:36:26 | INFO | fairseq.trainer | begin training epoch 16
2021-01-11 22:37:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:37:01 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 2.857 | nll_loss 2.355 | ppl 5.11 | wps 0 | wpb 1056 | bsz 18 | num_updates 224 | best_loss 2.857
2021-01-11 22:37:01 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:37:01 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint16.pt after 224 updates
2021-01-11 22:37:01 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint16.pt
2021-01-11 22:37:20 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint16.pt (epoch 16 @ 224 updates, score 2.857) (writing took 19.01120848581195 seconds)
2021-01-11 22:37:20 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2021-01-11 22:37:20 | INFO | train | epoch 016 | loss 2.919 | nll_loss 2.453 | ppl 5.48 | wps 426.2 | ups 0.26 | wpb 1624.6 | bsz 28.7 | num_updates 224 | lr 2.8e-05 | gnorm 2.187 | train_wall 33 | wall 853
2021-01-11 22:37:20 | INFO | fairseq.trainer | begin training epoch 17
2021-01-11 22:37:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:37:54 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 2.844 | nll_loss 2.347 | ppl 5.09 | wps 0 | wpb 1056 | bsz 18 | num_updates 238 | best_loss 2.844
2021-01-11 22:37:54 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:37:54 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint17.pt after 238 updates
2021-01-11 22:37:55 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint17.pt
2021-01-11 22:39:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint17.pt (epoch 17 @ 238 updates, score 2.844) (writing took 76.32335493341088 seconds)
2021-01-11 22:39:11 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2021-01-11 22:39:11 | INFO | train | epoch 017 | loss 2.912 | nll_loss 2.438 | ppl 5.42 | wps 205.1 | ups 0.13 | wpb 1624.6 | bsz 28.7 | num_updates 238 | lr 2.975e-05 | gnorm 1.946 | train_wall 34 | wall 963
2021-01-11 22:39:11 | INFO | fairseq.trainer | begin training epoch 18
2021-01-11 22:39:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:39:45 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 2.849 | nll_loss 2.359 | ppl 5.13 | wps 0 | wpb 1056 | bsz 18 | num_updates 252 | best_loss 2.844
2021-01-11 22:39:45 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:39:45 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint18.pt after 252 updates
2021-01-11 22:39:45 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint18.pt
2021-01-11 22:39:46 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint18.pt (epoch 18 @ 252 updates, score 2.849) (writing took 1.0052206628024578 seconds)
2021-01-11 22:39:46 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2021-01-11 22:39:46 | INFO | train | epoch 018 | loss 2.9 | nll_loss 2.423 | ppl 5.36 | wps 641.8 | ups 0.4 | wpb 1624.6 | bsz 28.7 | num_updates 252 | lr 3.15e-05 | gnorm 1.751 | train_wall 34 | wall 999
2021-01-11 22:39:46 | INFO | fairseq.trainer | begin training epoch 19
2021-01-11 22:40:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:40:20 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 2.839 | nll_loss 2.333 | ppl 5.04 | wps 0 | wpb 1056 | bsz 18 | num_updates 266 | best_loss 2.839
2021-01-11 22:40:20 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:40:20 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint19.pt after 266 updates
2021-01-11 22:40:20 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint19.pt
2021-01-11 22:40:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint19.pt (epoch 19 @ 266 updates, score 2.839) (writing took 1.7191813588142395 seconds)
2021-01-11 22:40:22 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2021-01-11 22:40:22 | INFO | train | epoch 019 | loss 2.897 | nll_loss 2.42 | ppl 5.35 | wps 633.3 | ups 0.39 | wpb 1624.6 | bsz 28.7 | num_updates 266 | lr 3.325e-05 | gnorm 2.039 | train_wall 33 | wall 1035
2021-01-11 22:40:22 | INFO | fairseq.trainer | begin training epoch 20
2021-01-11 22:40:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:40:56 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 2.847 | nll_loss 2.367 | ppl 5.16 | wps 0 | wpb 1056 | bsz 18 | num_updates 280 | best_loss 2.839
2021-01-11 22:40:56 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:40:56 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint20.pt after 280 updates
2021-01-11 22:40:57 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint20.pt
2021-01-11 22:40:57 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint20.pt (epoch 20 @ 280 updates, score 2.847) (writing took 1.0003677867352962 seconds)
2021-01-11 22:40:57 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2021-01-11 22:40:57 | INFO | train | epoch 020 | loss 2.941 | nll_loss 2.478 | ppl 5.57 | wps 640.7 | ups 0.39 | wpb 1624.6 | bsz 28.7 | num_updates 280 | lr 3.5e-05 | gnorm 4.025 | train_wall 34 | wall 1070
2021-01-11 22:40:57 | INFO | fairseq.trainer | begin training epoch 21
2021-01-11 22:41:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:41:32 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 2.856 | nll_loss 2.377 | ppl 5.19 | wps 0 | wpb 1056 | bsz 18 | num_updates 294 | best_loss 2.839
2021-01-11 22:41:32 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:41:32 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint21.pt after 294 updates
2021-01-11 22:41:32 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint21.pt
2021-01-11 22:41:33 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint21.pt (epoch 21 @ 294 updates, score 2.856) (writing took 1.0370173044502735 seconds)
2021-01-11 22:41:33 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2021-01-11 22:41:33 | INFO | train | epoch 021 | loss 2.938 | nll_loss 2.466 | ppl 5.53 | wps 642.1 | ups 0.4 | wpb 1624.6 | bsz 28.7 | num_updates 294 | lr 3.675e-05 | gnorm 3.578 | train_wall 33 | wall 1106
2021-01-11 22:41:33 | INFO | fairseq.trainer | begin training epoch 22
2021-01-11 22:42:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:42:07 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 2.84 | nll_loss 2.332 | ppl 5.03 | wps 0 | wpb 1056 | bsz 18 | num_updates 308 | best_loss 2.839
2021-01-11 22:42:07 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:42:07 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint22.pt after 308 updates
2021-01-11 22:42:08 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint22.pt
2021-01-11 22:42:08 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint22.pt (epoch 22 @ 308 updates, score 2.84) (writing took 1.0285739228129387 seconds)
2021-01-11 22:42:08 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2021-01-11 22:42:08 | INFO | train | epoch 022 | loss 2.886 | nll_loss 2.413 | ppl 5.33 | wps 638.3 | ups 0.39 | wpb 1624.6 | bsz 28.7 | num_updates 308 | lr 3.85e-05 | gnorm 1.957 | train_wall 34 | wall 1141
2021-01-11 22:42:08 | INFO | fairseq.trainer | begin training epoch 23
2021-01-11 22:42:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:42:43 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 2.85 | nll_loss 2.361 | ppl 5.14 | wps 0 | wpb 1056 | bsz 18 | num_updates 322 | best_loss 2.839
2021-01-11 22:42:43 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:42:43 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint23.pt after 322 updates
2021-01-11 22:42:43 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint23.pt
2021-01-11 22:42:44 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint23.pt (epoch 23 @ 322 updates, score 2.85) (writing took 1.001834373921156 seconds)
2021-01-11 22:42:44 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2021-01-11 22:42:44 | INFO | train | epoch 023 | loss 2.877 | nll_loss 2.402 | ppl 5.29 | wps 644 | ups 0.4 | wpb 1624.6 | bsz 28.7 | num_updates 322 | lr 4.025e-05 | gnorm 1.862 | train_wall 33 | wall 1177
2021-01-11 22:42:44 | INFO | fairseq.trainer | begin training epoch 24
2021-01-11 22:43:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:43:18 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 2.817 | nll_loss 2.301 | ppl 4.93 | wps 0 | wpb 1056 | bsz 18 | num_updates 336 | best_loss 2.817
2021-01-11 22:43:18 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:43:18 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint24.pt after 336 updates
2021-01-11 22:43:18 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint24.pt
2021-01-11 22:43:20 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint24.pt (epoch 24 @ 336 updates, score 2.817) (writing took 1.81860988214612 seconds)
2021-01-11 22:43:20 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2021-01-11 22:43:20 | INFO | train | epoch 024 | loss 2.868 | nll_loss 2.386 | ppl 5.23 | wps 630.6 | ups 0.39 | wpb 1624.6 | bsz 28.7 | num_updates 336 | lr 4.2e-05 | gnorm 1.861 | train_wall 33 | wall 1213
2021-01-11 22:43:20 | INFO | fairseq.trainer | begin training epoch 25
2021-01-11 22:43:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:43:54 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 2.859 | nll_loss 2.356 | ppl 5.12 | wps 0 | wpb 1056 | bsz 18 | num_updates 350 | best_loss 2.817
2021-01-11 22:43:54 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:43:54 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint25.pt after 350 updates
2021-01-11 22:43:54 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint25.pt
2021-01-11 22:43:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint25.pt (epoch 25 @ 350 updates, score 2.859) (writing took 1.0260444469749928 seconds)
2021-01-11 22:43:55 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2021-01-11 22:43:55 | INFO | train | epoch 025 | loss 2.863 | nll_loss 2.379 | ppl 5.2 | wps 643.1 | ups 0.4 | wpb 1624.6 | bsz 28.7 | num_updates 350 | lr 4.375e-05 | gnorm 1.948 | train_wall 33 | wall 1248
2021-01-11 22:43:55 | INFO | fairseq.trainer | begin training epoch 26
2021-01-11 22:44:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:44:30 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 2.822 | nll_loss 2.315 | ppl 4.98 | wps 0 | wpb 1056 | bsz 18 | num_updates 364 | best_loss 2.817
2021-01-11 22:44:30 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:44:30 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint26.pt after 364 updates
2021-01-11 22:44:30 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint26.pt
2021-01-11 22:44:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint26.pt (epoch 26 @ 364 updates, score 2.822) (writing took 1.0080534629523754 seconds)
2021-01-11 22:44:31 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2021-01-11 22:44:31 | INFO | train | epoch 026 | loss 2.882 | nll_loss 2.409 | ppl 5.31 | wps 643.7 | ups 0.4 | wpb 1624.6 | bsz 28.7 | num_updates 364 | lr 4.55e-05 | gnorm 2.816 | train_wall 33 | wall 1283
2021-01-11 22:44:31 | INFO | fairseq.trainer | begin training epoch 27
2021-01-11 22:45:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:45:05 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 2.825 | nll_loss 2.346 | ppl 5.08 | wps 0 | wpb 1056 | bsz 18 | num_updates 378 | best_loss 2.817
2021-01-11 22:45:05 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:45:05 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint27.pt after 378 updates
2021-01-11 22:45:05 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint27.pt
2021-01-11 22:45:06 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint27.pt (epoch 27 @ 378 updates, score 2.825) (writing took 1.0293896533548832 seconds)
2021-01-11 22:45:06 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2021-01-11 22:45:06 | INFO | train | epoch 027 | loss 2.869 | nll_loss 2.39 | ppl 5.24 | wps 643.5 | ups 0.4 | wpb 1624.6 | bsz 28.7 | num_updates 378 | lr 4.725e-05 | gnorm 2.39 | train_wall 33 | wall 1319
2021-01-11 22:45:06 | INFO | fairseq.trainer | begin training epoch 28
2021-01-11 22:45:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:45:40 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 2.903 | nll_loss 2.39 | ppl 5.24 | wps 0 | wpb 1056 | bsz 18 | num_updates 392 | best_loss 2.817
2021-01-11 22:45:40 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:45:40 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint28.pt after 392 updates
2021-01-11 22:45:40 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint28.pt
2021-01-11 22:45:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint28.pt (epoch 28 @ 392 updates, score 2.903) (writing took 11.546717654913664 seconds)
2021-01-11 22:45:52 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2021-01-11 22:45:52 | INFO | train | epoch 028 | loss 2.904 | nll_loss 2.444 | ppl 5.44 | wps 496.4 | ups 0.31 | wpb 1624.6 | bsz 28.7 | num_updates 392 | lr 4.9e-05 | gnorm 2.717 | train_wall 33 | wall 1365
2021-01-11 22:45:52 | INFO | fairseq.trainer | begin training epoch 29
2021-01-11 22:46:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:46:26 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 2.82 | nll_loss 2.302 | ppl 4.93 | wps 0 | wpb 1056 | bsz 18 | num_updates 406 | best_loss 2.817
2021-01-11 22:46:26 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:46:26 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint29.pt after 406 updates
2021-01-11 22:46:26 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint29.pt
2021-01-11 22:46:51 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint29.pt (epoch 29 @ 406 updates, score 2.82) (writing took 24.9687917008996 seconds)
2021-01-11 22:46:51 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2021-01-11 22:46:51 | INFO | train | epoch 029 | loss 2.896 | nll_loss 2.42 | ppl 5.35 | wps 382.3 | ups 0.24 | wpb 1624.6 | bsz 28.7 | num_updates 406 | lr 5.075e-05 | gnorm 2.93 | train_wall 34 | wall 1424
2021-01-11 22:46:51 | INFO | fairseq.trainer | begin training epoch 30
2021-01-11 22:47:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:47:26 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 2.83 | nll_loss 2.337 | ppl 5.05 | wps 0 | wpb 1056 | bsz 18 | num_updates 420 | best_loss 2.817
2021-01-11 22:47:26 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:47:26 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint30.pt after 420 updates
2021-01-11 22:47:26 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint30.pt
2021-01-11 22:47:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint30.pt (epoch 30 @ 420 updates, score 2.83) (writing took 21.910671792924404 seconds)
2021-01-11 22:47:48 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2021-01-11 22:47:48 | INFO | train | epoch 030 | loss 2.849 | nll_loss 2.363 | ppl 5.15 | wps 402.9 | ups 0.25 | wpb 1624.6 | bsz 28.7 | num_updates 420 | lr 5.25e-05 | gnorm 1.957 | train_wall 34 | wall 1481
2021-01-11 22:47:48 | INFO | fairseq.trainer | begin training epoch 31
2021-01-11 22:48:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:48:22 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 2.787 | nll_loss 2.276 | ppl 4.84 | wps 0 | wpb 1056 | bsz 18 | num_updates 434 | best_loss 2.787
2021-01-11 22:48:22 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:48:22 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint31.pt after 434 updates
2021-01-11 22:48:22 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint31.pt
2021-01-11 22:48:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint31.pt (epoch 31 @ 434 updates, score 2.787) (writing took 31.834916781634092 seconds)
2021-01-11 22:48:54 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2021-01-11 22:48:54 | INFO | train | epoch 031 | loss 2.849 | nll_loss 2.368 | ppl 5.16 | wps 343.2 | ups 0.21 | wpb 1624.6 | bsz 28.7 | num_updates 434 | lr 5.425e-05 | gnorm 2.3 | train_wall 34 | wall 1547
2021-01-11 22:48:54 | INFO | fairseq.trainer | begin training epoch 32
2021-01-11 22:49:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:49:28 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 2.805 | nll_loss 2.285 | ppl 4.87 | wps 0 | wpb 1056 | bsz 18 | num_updates 448 | best_loss 2.787
2021-01-11 22:49:28 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:49:28 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint32.pt after 448 updates
2021-01-11 22:49:28 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint32.pt
2021-01-11 22:49:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint32.pt (epoch 32 @ 448 updates, score 2.805) (writing took 25.40344997867942 seconds)
2021-01-11 22:49:54 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2021-01-11 22:49:54 | INFO | train | epoch 032 | loss 2.82 | nll_loss 2.334 | ppl 5.04 | wps 381.6 | ups 0.23 | wpb 1624.6 | bsz 28.7 | num_updates 448 | lr 5.6e-05 | gnorm 1.475 | train_wall 33 | wall 1606
2021-01-11 22:49:54 | INFO | fairseq.trainer | begin training epoch 33
2021-01-11 22:50:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:50:28 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 2.826 | nll_loss 2.301 | ppl 4.93 | wps 0 | wpb 1056 | bsz 18 | num_updates 462 | best_loss 2.787
2021-01-11 22:50:28 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:50:28 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint33.pt after 462 updates
2021-01-11 22:50:28 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint33.pt
2021-01-11 22:50:30 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint33.pt (epoch 33 @ 462 updates, score 2.826) (writing took 2.090150158852339 seconds)
2021-01-11 22:50:30 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2021-01-11 22:50:30 | INFO | train | epoch 033 | loss 2.82 | nll_loss 2.331 | ppl 5.03 | wps 624.1 | ups 0.38 | wpb 1624.6 | bsz 28.7 | num_updates 462 | lr 5.775e-05 | gnorm 2.092 | train_wall 33 | wall 1643
2021-01-11 22:50:30 | INFO | fairseq.trainer | begin training epoch 34
2021-01-11 22:51:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:51:04 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 2.833 | nll_loss 2.31 | ppl 4.96 | wps 0 | wpb 1056 | bsz 18 | num_updates 476 | best_loss 2.787
2021-01-11 22:51:04 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:51:04 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint34.pt after 476 updates
2021-01-11 22:51:04 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint34.pt
2021-01-11 22:51:05 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint34.pt (epoch 34 @ 476 updates, score 2.833) (writing took 1.0157201401889324 seconds)
2021-01-11 22:51:05 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2021-01-11 22:51:05 | INFO | train | epoch 034 | loss 2.817 | nll_loss 2.331 | ppl 5.03 | wps 645.4 | ups 0.4 | wpb 1624.6 | bsz 28.7 | num_updates 476 | lr 5.95e-05 | gnorm 2.553 | train_wall 33 | wall 1678
2021-01-11 22:51:05 | INFO | fairseq.trainer | begin training epoch 35
2021-01-11 22:51:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:51:39 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 2.855 | nll_loss 2.359 | ppl 5.13 | wps 0 | wpb 1056 | bsz 18 | num_updates 490 | best_loss 2.787
2021-01-11 22:51:39 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:51:39 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint35.pt after 490 updates
2021-01-11 22:51:40 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint35.pt
2021-01-11 22:51:40 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint35.pt (epoch 35 @ 490 updates, score 2.855) (writing took 1.0320910923182964 seconds)
2021-01-11 22:51:40 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2021-01-11 22:51:40 | INFO | train | epoch 035 | loss 2.837 | nll_loss 2.359 | ppl 5.13 | wps 646.8 | ups 0.4 | wpb 1624.6 | bsz 28.7 | num_updates 490 | lr 6.125e-05 | gnorm 3.127 | train_wall 33 | wall 1713
2021-01-11 22:51:40 | INFO | fairseq.trainer | begin training epoch 36
2021-01-11 22:52:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:52:15 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 2.868 | nll_loss 2.343 | ppl 5.07 | wps 0 | wpb 1056 | bsz 18 | num_updates 504 | best_loss 2.787
2021-01-11 22:52:15 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:52:15 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint36.pt after 504 updates
2021-01-11 22:52:15 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint36.pt
2021-01-11 22:52:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint36.pt (epoch 36 @ 504 updates, score 2.868) (writing took 0.9751854278147221 seconds)
2021-01-11 22:52:16 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2021-01-11 22:52:16 | INFO | train | epoch 036 | loss 2.828 | nll_loss 2.341 | ppl 5.07 | wps 647.5 | ups 0.4 | wpb 1624.6 | bsz 28.7 | num_updates 504 | lr 6.3e-05 | gnorm 2.823 | train_wall 33 | wall 1748
2021-01-11 22:52:16 | INFO | fairseq.trainer | begin training epoch 37
2021-01-11 22:52:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:52:50 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 2.805 | nll_loss 2.27 | ppl 4.82 | wps 0 | wpb 1056 | bsz 18 | num_updates 518 | best_loss 2.787
2021-01-11 22:52:50 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:52:50 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint37.pt after 518 updates
2021-01-11 22:52:50 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint37.pt
2021-01-11 22:53:07 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint37.pt (epoch 37 @ 518 updates, score 2.805) (writing took 17.200409401208162 seconds)
2021-01-11 22:53:07 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2021-01-11 22:53:07 | INFO | train | epoch 037 | loss 2.855 | nll_loss 2.376 | ppl 5.19 | wps 441 | ups 0.27 | wpb 1624.6 | bsz 28.7 | num_updates 518 | lr 6.475e-05 | gnorm 3.174 | train_wall 33 | wall 1800
2021-01-11 22:53:07 | INFO | fairseq.trainer | begin training epoch 38
2021-01-11 22:53:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:53:41 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 2.809 | nll_loss 2.295 | ppl 4.91 | wps 0 | wpb 1056 | bsz 18 | num_updates 532 | best_loss 2.787
2021-01-11 22:53:41 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:53:41 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint38.pt after 532 updates
2021-01-11 22:53:41 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint38.pt
2021-01-11 22:53:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint38.pt (epoch 38 @ 532 updates, score 2.809) (writing took 11.498376600444317 seconds)
2021-01-11 22:53:53 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2021-01-11 22:53:53 | INFO | train | epoch 038 | loss 2.841 | nll_loss 2.361 | ppl 5.14 | wps 500.3 | ups 0.31 | wpb 1624.6 | bsz 28.7 | num_updates 532 | lr 6.65e-05 | gnorm 3.175 | train_wall 33 | wall 1845
2021-01-11 22:53:53 | INFO | fairseq.trainer | begin training epoch 39
2021-01-11 22:54:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:54:27 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 2.747 | nll_loss 2.219 | ppl 4.66 | wps 0 | wpb 1056 | bsz 18 | num_updates 546 | best_loss 2.747
2021-01-11 22:54:27 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:54:27 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint39.pt after 546 updates
2021-01-11 22:54:27 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint39.pt
2021-01-11 22:54:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint39.pt (epoch 39 @ 546 updates, score 2.747) (writing took 31.25379740819335 seconds)
2021-01-11 22:54:58 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2021-01-11 22:54:58 | INFO | train | epoch 039 | loss 2.793 | nll_loss 2.307 | ppl 4.95 | wps 346 | ups 0.21 | wpb 1624.6 | bsz 28.7 | num_updates 546 | lr 6.825e-05 | gnorm 2.146 | train_wall 34 | wall 1911
2021-01-11 22:54:58 | INFO | fairseq.trainer | begin training epoch 40
2021-01-11 22:55:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:55:32 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 2.707 | nll_loss 2.173 | ppl 4.51 | wps 0 | wpb 1056 | bsz 18 | num_updates 560 | best_loss 2.707
2021-01-11 22:55:32 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:55:32 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint40.pt after 560 updates
2021-01-11 22:55:33 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint40.pt
2021-01-11 22:55:59 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint40.pt (epoch 40 @ 560 updates, score 2.707) (writing took 26.056344650685787 seconds)
2021-01-11 22:55:59 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2021-01-11 22:55:59 | INFO | train | epoch 040 | loss 2.744 | nll_loss 2.241 | ppl 4.73 | wps 377.6 | ups 0.23 | wpb 1624.6 | bsz 28.7 | num_updates 560 | lr 7e-05 | gnorm 2.053 | train_wall 33 | wall 1971
2021-01-11 22:55:59 | INFO | fairseq.trainer | begin training epoch 41
2021-01-11 22:56:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:56:33 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 2.814 | nll_loss 2.277 | ppl 4.85 | wps 0 | wpb 1056 | bsz 18 | num_updates 574 | best_loss 2.707
2021-01-11 22:56:33 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:56:33 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint41.pt after 574 updates
2021-01-11 22:56:33 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint41.pt
2021-01-11 22:56:46 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint41.pt (epoch 41 @ 574 updates, score 2.814) (writing took 13.272764407098293 seconds)
2021-01-11 22:56:46 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2021-01-11 22:56:46 | INFO | train | epoch 041 | loss 2.799 | nll_loss 2.314 | ppl 4.97 | wps 479.6 | ups 0.3 | wpb 1624.6 | bsz 28.7 | num_updates 574 | lr 7.175e-05 | gnorm 2.93 | train_wall 33 | wall 2019
2021-01-11 22:56:46 | INFO | fairseq.trainer | begin training epoch 42
2021-01-11 22:57:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:57:20 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 2.801 | nll_loss 2.267 | ppl 4.81 | wps 0 | wpb 1056 | bsz 18 | num_updates 588 | best_loss 2.707
2021-01-11 22:57:20 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:57:20 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint42.pt after 588 updates
2021-01-11 22:57:20 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint42.pt
2021-01-11 22:57:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint42.pt (epoch 42 @ 588 updates, score 2.801) (writing took 2.0693092308938503 seconds)
2021-01-11 22:57:22 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2021-01-11 22:57:22 | INFO | train | epoch 042 | loss 2.759 | nll_loss 2.27 | ppl 4.82 | wps 627.9 | ups 0.39 | wpb 1624.6 | bsz 28.7 | num_updates 588 | lr 7.35e-05 | gnorm 2.467 | train_wall 33 | wall 2055
2021-01-11 22:57:22 | INFO | fairseq.trainer | begin training epoch 43
2021-01-11 22:57:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:57:57 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 2.681 | nll_loss 2.128 | ppl 4.37 | wps 0 | wpb 1056 | bsz 18 | num_updates 602 | best_loss 2.681
2021-01-11 22:57:57 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:57:57 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint43.pt after 602 updates
2021-01-11 22:57:57 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint43.pt
2021-01-11 22:57:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint43.pt (epoch 43 @ 602 updates, score 2.681) (writing took 1.7900674678385258 seconds)
2021-01-11 22:57:58 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2021-01-11 22:57:58 | INFO | train | epoch 043 | loss 2.73 | nll_loss 2.219 | ppl 4.65 | wps 625.8 | ups 0.39 | wpb 1624.6 | bsz 28.7 | num_updates 602 | lr 7.525e-05 | gnorm 2.31 | train_wall 34 | wall 2091
2021-01-11 22:57:59 | INFO | fairseq.trainer | begin training epoch 44
2021-01-11 22:58:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:58:33 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 2.739 | nll_loss 2.223 | ppl 4.67 | wps 0 | wpb 1056 | bsz 18 | num_updates 616 | best_loss 2.681
2021-01-11 22:58:33 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:58:33 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint44.pt after 616 updates
2021-01-11 22:58:33 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint44.pt
2021-01-11 22:58:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint44.pt (epoch 44 @ 616 updates, score 2.739) (writing took 1.0038878805935383 seconds)
2021-01-11 22:58:34 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2021-01-11 22:58:34 | INFO | train | epoch 044 | loss 2.705 | nll_loss 2.205 | ppl 4.61 | wps 646.4 | ups 0.4 | wpb 1624.6 | bsz 28.7 | num_updates 616 | lr 7.7e-05 | gnorm 2.279 | train_wall 33 | wall 2127
2021-01-11 22:58:34 | INFO | fairseq.trainer | begin training epoch 45
2021-01-11 22:59:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:59:08 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 2.684 | nll_loss 2.099 | ppl 4.28 | wps 0 | wpb 1056 | bsz 18 | num_updates 630 | best_loss 2.681
2021-01-11 22:59:08 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:59:08 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint45.pt after 630 updates
2021-01-11 22:59:08 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint45.pt
2021-01-11 22:59:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint45.pt (epoch 45 @ 630 updates, score 2.684) (writing took 1.0054074451327324 seconds)
2021-01-11 22:59:09 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2021-01-11 22:59:09 | INFO | train | epoch 045 | loss 2.689 | nll_loss 2.187 | ppl 4.55 | wps 644.9 | ups 0.4 | wpb 1624.6 | bsz 28.7 | num_updates 630 | lr 7.875e-05 | gnorm 1.986 | train_wall 33 | wall 2162
2021-01-11 22:59:09 | INFO | fairseq.trainer | begin training epoch 46
2021-01-11 22:59:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 22:59:43 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 2.612 | nll_loss 2.079 | ppl 4.23 | wps 0 | wpb 1056 | bsz 18 | num_updates 644 | best_loss 2.612
2021-01-11 22:59:43 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 22:59:43 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint46.pt after 644 updates
2021-01-11 22:59:44 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint46.pt
2021-01-11 22:59:45 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint46.pt (epoch 46 @ 644 updates, score 2.612) (writing took 1.7634213753044605 seconds)
2021-01-11 22:59:45 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2021-01-11 22:59:45 | INFO | train | epoch 046 | loss 2.656 | nll_loss 2.141 | ppl 4.41 | wps 628.9 | ups 0.39 | wpb 1624.6 | bsz 28.7 | num_updates 644 | lr 8.05e-05 | gnorm 1.701 | train_wall 34 | wall 2198
2021-01-11 22:59:45 | INFO | fairseq.trainer | begin training epoch 47
2021-01-11 23:00:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 23:00:19 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 2.664 | nll_loss 2.143 | ppl 4.42 | wps 0 | wpb 1056 | bsz 18 | num_updates 658 | best_loss 2.612
2021-01-11 23:00:19 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 23:00:19 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint47.pt after 658 updates
2021-01-11 23:00:19 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint47.pt
2021-01-11 23:00:20 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint47.pt (epoch 47 @ 658 updates, score 2.664) (writing took 1.019754994660616 seconds)
2021-01-11 23:00:20 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2021-01-11 23:00:20 | INFO | train | epoch 047 | loss 2.684 | nll_loss 2.175 | ppl 4.51 | wps 648.3 | ups 0.4 | wpb 1624.6 | bsz 28.7 | num_updates 658 | lr 8.225e-05 | gnorm 2.395 | train_wall 33 | wall 2233
2021-01-11 23:00:20 | INFO | fairseq.trainer | begin training epoch 48
2021-01-11 23:00:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 23:00:54 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 2.657 | nll_loss 2.108 | ppl 4.31 | wps 0 | wpb 1056 | bsz 18 | num_updates 672 | best_loss 2.612
2021-01-11 23:00:54 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 23:00:54 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint48.pt after 672 updates
2021-01-11 23:00:55 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint48.pt
2021-01-11 23:00:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint48.pt (epoch 48 @ 672 updates, score 2.657) (writing took 0.9885650239884853 seconds)
2021-01-11 23:00:55 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2021-01-11 23:00:55 | INFO | train | epoch 048 | loss 2.706 | nll_loss 2.206 | ppl 4.61 | wps 647.4 | ups 0.4 | wpb 1624.6 | bsz 28.7 | num_updates 672 | lr 8.4e-05 | gnorm 2.802 | train_wall 33 | wall 2268
2021-01-11 23:00:55 | INFO | fairseq.trainer | begin training epoch 49
2021-01-11 23:01:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 23:01:30 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 2.833 | nll_loss 2.314 | ppl 4.97 | wps 0 | wpb 1056 | bsz 18 | num_updates 686 | best_loss 2.612
2021-01-11 23:01:30 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 23:01:30 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint49.pt after 686 updates
2021-01-11 23:01:30 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint49.pt
2021-01-11 23:01:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint49.pt (epoch 49 @ 686 updates, score 2.833) (writing took 27.875984396785498 seconds)
2021-01-11 23:01:58 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2021-01-11 23:01:58 | INFO | train | epoch 049 | loss 2.677 | nll_loss 2.166 | ppl 4.49 | wps 364.9 | ups 0.22 | wpb 1624.6 | bsz 28.7 | num_updates 686 | lr 8.575e-05 | gnorm 2.753 | train_wall 34 | wall 2331
2021-01-11 23:01:58 | INFO | fairseq.trainer | begin training epoch 50
2021-01-11 23:02:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 23:02:32 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 2.658 | nll_loss 2.128 | ppl 4.37 | wps 0 | wpb 1056 | bsz 18 | num_updates 700 | best_loss 2.612
2021-01-11 23:02:32 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 23:02:32 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint50.pt after 700 updates
2021-01-11 23:02:32 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint50.pt
2021-01-11 23:02:44 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint50.pt (epoch 50 @ 700 updates, score 2.658) (writing took 11.728426530957222 seconds)
2021-01-11 23:02:44 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2021-01-11 23:02:44 | INFO | train | epoch 050 | loss 2.703 | nll_loss 2.208 | ppl 4.62 | wps 493.3 | ups 0.3 | wpb 1624.6 | bsz 28.7 | num_updates 700 | lr 8.75e-05 | gnorm 2.446 | train_wall 33 | wall 2377
2021-01-11 23:02:44 | INFO | fairseq.trainer | begin training epoch 51
2021-01-11 23:03:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 23:03:18 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 2.61 | nll_loss 2.051 | ppl 4.14 | wps 0 | wpb 1056 | bsz 18 | num_updates 714 | best_loss 2.61
2021-01-11 23:03:18 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 23:03:18 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint51.pt after 714 updates
2021-01-11 23:03:18 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint51.pt
2021-01-11 23:03:51 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint51.pt (epoch 51 @ 714 updates, score 2.61) (writing took 32.38034372404218 seconds)
2021-01-11 23:03:51 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2021-01-11 23:03:51 | INFO | train | epoch 051 | loss 2.646 | nll_loss 2.141 | ppl 4.41 | wps 340.5 | ups 0.21 | wpb 1624.6 | bsz 28.7 | num_updates 714 | lr 8.925e-05 | gnorm 1.96 | train_wall 34 | wall 2443
2021-01-11 23:03:51 | INFO | fairseq.trainer | begin training epoch 52
2021-01-11 23:04:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 23:04:25 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 2.574 | nll_loss 2.01 | ppl 4.03 | wps 0 | wpb 1056 | bsz 18 | num_updates 728 | best_loss 2.574
2021-01-11 23:04:25 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 23:04:25 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint52.pt after 728 updates
2021-01-11 23:04:25 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint52.pt
2021-01-11 23:04:45 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint52.pt (epoch 52 @ 728 updates, score 2.574) (writing took 19.477864608168602 seconds)
2021-01-11 23:04:45 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2021-01-11 23:04:45 | INFO | train | epoch 052 | loss 2.623 | nll_loss 2.107 | ppl 4.31 | wps 420.6 | ups 0.26 | wpb 1624.6 | bsz 28.7 | num_updates 728 | lr 9.1e-05 | gnorm 1.846 | train_wall 34 | wall 2497
2021-01-11 23:04:45 | INFO | fairseq.trainer | begin training epoch 53
2021-01-11 23:05:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 23:05:19 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 2.641 | nll_loss 2.09 | ppl 4.26 | wps 0 | wpb 1056 | bsz 18 | num_updates 742 | best_loss 2.574
2021-01-11 23:05:19 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 23:05:19 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint53.pt after 742 updates
2021-01-11 23:05:19 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint53.pt
2021-01-11 23:05:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint53.pt (epoch 53 @ 742 updates, score 2.641) (writing took 22.663797207176685 seconds)
2021-01-11 23:05:41 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2021-01-11 23:05:41 | INFO | train | epoch 053 | loss 2.603 | nll_loss 2.089 | ppl 4.25 | wps 400 | ups 0.25 | wpb 1624.6 | bsz 28.7 | num_updates 742 | lr 9.275e-05 | gnorm 1.675 | train_wall 33 | wall 2554
2021-01-11 23:05:42 | INFO | fairseq.trainer | begin training epoch 54
2021-01-11 23:06:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 23:06:16 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 2.606 | nll_loss 2.04 | ppl 4.11 | wps 0 | wpb 1056 | bsz 18 | num_updates 756 | best_loss 2.574
2021-01-11 23:06:16 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 23:06:16 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint54.pt after 756 updates
2021-01-11 23:06:16 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint54.pt
2021-01-11 23:06:19 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint54.pt (epoch 54 @ 756 updates, score 2.606) (writing took 3.1006569117307663 seconds)
2021-01-11 23:06:19 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2021-01-11 23:06:19 | INFO | train | epoch 054 | loss 2.602 | nll_loss 2.084 | ppl 4.24 | wps 609.4 | ups 0.38 | wpb 1624.6 | bsz 28.7 | num_updates 756 | lr 9.45e-05 | gnorm 1.73 | train_wall 33 | wall 2592
2021-01-11 23:06:19 | INFO | fairseq.trainer | begin training epoch 55
2021-01-11 23:06:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 23:06:53 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 2.671 | nll_loss 2.098 | ppl 4.28 | wps 0 | wpb 1056 | bsz 18 | num_updates 770 | best_loss 2.574
2021-01-11 23:06:53 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 23:06:53 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint55.pt after 770 updates
2021-01-11 23:06:53 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint55.pt
2021-01-11 23:07:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint55.pt (epoch 55 @ 770 updates, score 2.671) (writing took 28.395692639052868 seconds)
2021-01-11 23:07:21 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2021-01-11 23:07:21 | INFO | train | epoch 055 | loss 2.598 | nll_loss 2.08 | ppl 4.23 | wps 363 | ups 0.22 | wpb 1624.6 | bsz 28.7 | num_updates 770 | lr 9.625e-05 | gnorm 1.985 | train_wall 33 | wall 2654
2021-01-11 23:07:21 | INFO | fairseq.trainer | begin training epoch 56
2021-01-11 23:07:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 23:07:56 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 2.652 | nll_loss 2.079 | ppl 4.23 | wps 0 | wpb 1056 | bsz 18 | num_updates 784 | best_loss 2.574
2021-01-11 23:07:56 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 23:07:56 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint56.pt after 784 updates
2021-01-11 23:07:56 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint56.pt
2021-01-11 23:08:07 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint56.pt (epoch 56 @ 784 updates, score 2.652) (writing took 11.581081300973892 seconds)
2021-01-11 23:08:07 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2021-01-11 23:08:07 | INFO | train | epoch 056 | loss 2.667 | nll_loss 2.169 | ppl 4.5 | wps 495.9 | ups 0.31 | wpb 1624.6 | bsz 28.7 | num_updates 784 | lr 9.8e-05 | gnorm 2.54 | train_wall 33 | wall 2700
2021-01-11 23:08:07 | INFO | fairseq.trainer | begin training epoch 57
2021-01-11 23:08:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 23:08:41 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 2.624 | nll_loss 2.09 | ppl 4.26 | wps 0 | wpb 1056 | bsz 18 | num_updates 798 | best_loss 2.574
2021-01-11 23:08:41 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 23:08:41 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint57.pt after 798 updates
2021-01-11 23:08:42 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint57.pt
2021-01-11 23:09:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint57.pt (epoch 57 @ 798 updates, score 2.624) (writing took 19.980010647326708 seconds)
2021-01-11 23:09:01 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2021-01-11 23:09:01 | INFO | train | epoch 057 | loss 2.641 | nll_loss 2.121 | ppl 4.35 | wps 420.6 | ups 0.26 | wpb 1624.6 | bsz 28.7 | num_updates 798 | lr 9.975e-05 | gnorm 1.798 | train_wall 33 | wall 2754
2021-01-11 23:09:01 | INFO | fairseq.trainer | begin training epoch 58
2021-01-11 23:09:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 23:09:36 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 2.671 | nll_loss 2.083 | ppl 4.24 | wps 0 | wpb 1056 | bsz 18 | num_updates 812 | best_loss 2.574
2021-01-11 23:09:36 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 23:09:36 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint58.pt after 812 updates
2021-01-11 23:09:36 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint58.pt
2021-01-11 23:09:37 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint58.pt (epoch 58 @ 812 updates, score 2.671) (writing took 0.9899555332958698 seconds)
2021-01-11 23:09:37 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2021-01-11 23:09:37 | INFO | train | epoch 058 | loss 2.623 | nll_loss 2.105 | ppl 4.3 | wps 643.5 | ups 0.4 | wpb 1624.6 | bsz 28.7 | num_updates 812 | lr 0.0001015 | gnorm 2.012 | train_wall 33 | wall 2790
2021-01-11 23:09:37 | INFO | fairseq.trainer | begin training epoch 59
2021-01-11 23:10:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 23:10:11 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 2.651 | nll_loss 2.112 | ppl 4.32 | wps 0 | wpb 1056 | bsz 18 | num_updates 826 | best_loss 2.574
2021-01-11 23:10:11 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 23:10:11 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint59.pt after 826 updates
2021-01-11 23:10:11 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint59.pt
2021-01-11 23:10:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint59.pt (epoch 59 @ 826 updates, score 2.651) (writing took 0.98509756103158 seconds)
2021-01-11 23:10:12 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2021-01-11 23:10:12 | INFO | train | epoch 059 | loss 2.694 | nll_loss 2.193 | ppl 4.57 | wps 645.5 | ups 0.4 | wpb 1624.6 | bsz 28.7 | num_updates 826 | lr 0.00010325 | gnorm 2.7 | train_wall 33 | wall 2825
2021-01-11 23:10:12 | INFO | fairseq.trainer | begin training epoch 60
2021-01-11 23:10:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 23:10:46 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 2.71 | nll_loss 2.16 | ppl 4.47 | wps 0 | wpb 1056 | bsz 18 | num_updates 840 | best_loss 2.574
2021-01-11 23:10:46 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 23:10:46 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint60.pt after 840 updates
2021-01-11 23:10:47 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint60.pt
2021-01-11 23:10:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint60.pt (epoch 60 @ 840 updates, score 2.71) (writing took 0.9941560961306095 seconds)
2021-01-11 23:10:47 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2021-01-11 23:10:47 | INFO | train | epoch 060 | loss 2.615 | nll_loss 2.101 | ppl 4.29 | wps 644.6 | ups 0.4 | wpb 1624.6 | bsz 28.7 | num_updates 840 | lr 0.000105 | gnorm 1.988 | train_wall 33 | wall 2860
2021-01-11 23:10:47 | INFO | fairseq.trainer | begin training epoch 61
2021-01-11 23:11:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-01-11 23:11:22 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 2.608 | nll_loss 2.065 | ppl 4.18 | wps 0 | wpb 1056 | bsz 18 | num_updates 854 | best_loss 2.574
2021-01-11 23:11:22 | INFO | fairseq_cli.train | begin save checkpoint
2021-01-11 23:11:22 | INFO | fairseq.trainer | Preparing to save checkpoint to checkpoints/checkpoint61.pt after 854 updates
2021-01-11 23:11:22 | INFO | fairseq.trainer | Finished saving checkpoint to checkpoints/checkpoint61.pt
2021-01-11 23:11:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint61.pt (epoch 61 @ 854 updates, score 2.608) (writing took 1.0054981410503387 seconds)
2021-01-11 23:11:23 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2021-01-11 23:11:23 | INFO | train | epoch 061 | loss 2.647 | nll_loss 2.15 | ppl 4.44 | wps 645.1 | ups 0.4 | wpb 1624.6 | bsz 28.7 | num_updates 854 | lr 0.00010675 | gnorm 2.57 | train_wall 33 | wall 2895
2021-01-11 23:11:23 | INFO | fairseq.trainer | begin training epoch 62
